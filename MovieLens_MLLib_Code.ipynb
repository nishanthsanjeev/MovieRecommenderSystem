{
  "metadata": {
    "name": "BDAD MovieLens",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\n# wget https://files.grouplens.org/datasets/movielens/ml-25m.zip\n# unzip ml-25m.zip\n# ls\n# hadoop fs -ls"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "%sh\nspark-shell --deploy-mode client"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val movieSchema \u003d \"movieId INT, title STRING, genres STRING\"\nval df_movies \u003d spark.read.format(\"csv\").schema(movieSchema).option(\"header\", \"true\").load(\"ml-25m/movies.csv\")\n//df_movies.show(25, false)\n\nval ratingSchema \u003d \"userId INT, movieId INT, rating DOUBLE, timestamp LONG\"\nval df_ratings_timestamp \u003d spark.read.format(\"csv\").schema(ratingSchema).option(\"header\", \"true\").load(\"ml-25m/ratings.csv\")\nval df_ratings \u003d df_ratings_timestamp.drop(\"timestamp\")\n//df_ratings.show(25, false)\n\n\n// sc.stop()\n\n\n\n//Commands to try training an ALS model:\n\n\nval set \u003d df_ratings.randomSplit(Array(0.8, 0.2))\nval training \u003d set(0).cache()\nval test \u003d set(1).cache()\n//training.take(5).foreach(println)\n\nprintln(s\"Training: ${training.count()}, test: ${test.count()}\")"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "import org.apache.spark.ml.recommendation.ALS\nimport org.apache.spark.ml.recommendation.ALSModel\nimport org.apache.spark.ml.evaluation.RegressionEvaluator\n\n\n// Build the recommendation model using ALS on the training data\nval als \u003d new ALS()\n  .setMaxIter(15)\n  .setRank(10)\n  .setRegParam(0.01)\n  .setUserCol(\"userId\")\n  .setItemCol(\"movieId\")\n  .setRatingCol(\"rating\")\nval model \u003d als.fit(training)\n\n// Evaluate the model by computing the RMSE on the test data\n// Note we set cold start strategy to \u0027drop\u0027 to ensure we don\u0027t get NaN evaluation metrics\nmodel.setColdStartStrategy(\"drop\")\n// model.save(\"target/tmp/myCollaborativeFilter\")\n// val model \u003d ALSModel.load(\"target/tmp/myCollaborativeFilter\")\nval predictions \u003d model.transform(test)\n\nval evaluator \u003d new RegressionEvaluator()\n  .setMetricName(\"rmse\")\n  .setLabelCol(\"rating\")\n  .setPredictionCol(\"prediction\")\nval rmse \u003d evaluator.evaluate(predictions)\nprintln(s\"Root-mean-square error \u003d $rmse\")"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "predictions.show(25)"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Generate top 10 movie recommendations for each user\nval userRecs \u003d model.recommendForAllUsers(10)\n// Generate top 10 user recommendations for each movie\nval movieRecs \u003d model.recommendForAllItems(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// For user 148:\n\n// Generate list of movies that he has rated with atleast 4.0 score out of 5. Get this from df_movies\n// Check the predictions that i have made for user 148 with atleast 4.0 out of 5. Get this from predictions\n// See if those movies are similar based on genre , year? and tags?\n\n// If so, my analytic\u0027s goodness is shown!"
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "// Join predictions.filter(userId \u003d\u003d\u003d 148)\n// with df_movies on movieId\n\nval predictions148 \u003d predictions.filter(predictions(\"userId\") \u003d\u003d\u003d 148)\nval predictions148NoUser \u003d predictions148.drop(\"userId\")"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val predShow \u003d df_movies.join(predictions148NoUser, df_movies(\"movieId\") \u003d\u003d\u003d predictions148NoUser(\"movieId\"))"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val predShowFinal \u003d predShow.drop(\"movieId\")"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "predShowFinal.show(15, false)"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val arrMovies148 \u003d model.transform (test.where(test(\"userId\") \u003d\u003d\u003d 148))\n    .select (\u0027movieId, \u0027prediction)\n    .orderBy(\u0027prediction.desc)\n    .limit(10)\n    .toDF()"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "arrMovies148.show(10)"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val movies148 \u003d df_movies.join(arrMovies148, df_movies(\"movieId\") \u003d\u003d\u003d arrMovies148(\"movieId\")).drop(\"movieId\")"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "movies148.show(10, false)"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val ratings148 \u003d df_ratings.filter(df_ratings(\"userId\") \u003d\u003d\u003d 148 \u0026\u0026 df_ratings(\"rating\") \u003d\u003d\u003d 5.0)"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "ratings148.join(df_movies, df_movies(\"movieId\") \u003d\u003d\u003d ratings148(\"movieId\")).drop(\"movieId\", \"userId\").show(10, false)"
    }
  ]
}